{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## Основы pytorch",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Для выполнения ДЗ создайте приватный репозиторий и добавьте `https://github.com/norsage` в collaborators (Settings -> Collaborators -> Add people)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pip install torch",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'OSError'>",
          "evalue": "Not available",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minstall torch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2478\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2480\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/IPython/core/magics/packaging.py:92\u001b[0m, in \u001b[0;36mPackagingMagics.pip\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     python \u001b[38;5;241m=\u001b[39m shlex\u001b[38;5;241m.\u001b[39mquote(python)\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpython\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-m\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote: you may need to restart the kernel to use updated packages.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2653\u001b[0m, in \u001b[0;36mInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m   2648\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBackground processes not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2650\u001b[0m \u001b[38;5;66;03m# we explicitly do NOT return the subprocess status code, because\u001b[39;00m\n\u001b[1;32m   2651\u001b[0m \u001b[38;5;66;03m# a non-None value would trigger :func:`sys.displayhook` calls.\u001b[39;00m\n\u001b[1;32m   2652\u001b[0m \u001b[38;5;66;03m# Instead, we store the exit_code in user_ns.\u001b[39;00m\n\u001b[0;32m-> 2653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/IPython/utils/_process_emscripten.py:11\u001b[0m, in \u001b[0;36msystem\u001b[0;34m(cmd)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msystem\u001b[39m(cmd):\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot available\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mOSError\u001b[0m: Not available"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": "import torch",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'ModuleNotFoundError'>",
          "evalue": "No module named 'torch'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "#### 1. Операции над тензорами (1 балл)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "##### 1.1 Среднее значение по столбцам",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "torch.manual_seed(42)\nx = torch.randint(10, size=(2, 3)).float()\nx",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2., 7., 6.],\n",
              "        [4., 6., 5.]])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "mean_by_row = x.mean(dim=0)\nassert torch.allclose(\n    mean_by_row, _expected := torch.tensor([3.0, 6.5, 5.5])\n), f\"{mean_by_row} != {_expected}\"",
      "metadata": {},
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "##### 1.2. Взвешенное среднее\nВ тензоре `w` находятся ненормализованные веса для расчёта взвешенных средних тензора `x` по строкам.\n\nНайдите эти взвешенные средние, получая нормализованные веса с помощью функции `torch.softmax` (или метода `.softmax`)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "torch.manual_seed(42)\nx = torch.randint(10, size=(2, 3)).float()\nw = torch.randint(10, size=(2, 3)).float()\nprint(x)\nprint(w)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[2., 7., 6.],\n",
            "        [4., 6., 5.]])\n",
            "tensor([[0., 4., 0.],\n",
            "        [3., 8., 4.]])\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": "w_avg = (w.softmax(dim=1) * x).sum(dim=1)\nassert torch.allclose(\n    w_avg, _expected := torch.tensor([6.8940, 5.9690])\n), f\"{w_avg} != {_expected}\"",
      "metadata": {},
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "##### 1.3. Умножение матриц на векторы\n\nВ тензоре `m` - две матрицы, нужно сделать тензор, в котором i-й элемент - результат умножения матрицы `m[i]` на вектор `x[i]`.\n\nЭто можно было бы сделать так: `torch.stack([m[i] @ x[i] for i in len(m)])`.\n\nПопробуйте найти решение без цикла.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "torch.manual_seed(42)\nx = torch.randint(10, size=(2, 3)).float()\nm = torch.randint(10, size=(2, 3, 3)).float()\nprint(m)\nprint(x)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[0., 4., 0.],\n",
            "         [3., 8., 4.],\n",
            "         [0., 4., 1.]],\n",
            "\n",
            "        [[2., 5., 5.],\n",
            "         [7., 6., 9.],\n",
            "         [6., 3., 1.]]])\n",
            "tensor([[2., 7., 6.],\n",
            "        [4., 6., 5.]])\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": "matmul = torch.diagonal(torch.transpose(m @ x.T, 1, 2), dim1=0, dim2=1).T\nassert torch.allclose(\n    matmul, _expected := torch.tensor([[28.0, 86.0, 34.0], [63.0, 109.0, 47.0]])\n), f\"{matmul} != {_expected}\"",
      "metadata": {},
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "##### 1.4. Матрица попарных расстояний\n\nДаны две матрицы `x` и `y`, нужно получить матрицу `d`, где `d[i, j]` - евклидово расстояние между векторами `x[i]` и `y[j]`.\n\nПодсказка 1: воспользуйтесь broadcasting и добавлением размерностей в исходные тензоры.\n\nПодсказка 2: можно не считать евклидово расстояние вручную, есть функция `torch.linalg.norm`\n\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "torch.manual_seed(42)\nx = torch.randint(10, size=(2, 3)).float()\ny = torch.randint(10, size=(3, 3)).float()\nprint(x)\nprint(y)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[2., 7., 6.],\n",
            "        [4., 6., 5.]])\n",
            "tensor([[0., 4., 0.],\n",
            "        [3., 8., 4.],\n",
            "        [0., 4., 1.]])\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": "pdist = torch.linalg.norm(x.unsqueeze(1) - y, dim=2)\nassert torch.allclose(\n    pdist,\n    _expected := torch.tensor([[7.0000, 2.4495, 6.1644], [6.7082, 2.4495, 6.0000]]),\n), f\"{pdist} != {_expected}\"",
      "metadata": {},
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": "#### 2. Функция Power (1 балл)\nИспользуя сложение и умножение, реализуйте возведение в целочисленную степень FloatTensor как функцию autograd (т.е. наследника `torch.autograd.Function`)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "class Power(torch.autograd.Function):\n    @staticmethod\n    def forward(tensor, p):\n        return tensor**p\n\n    @staticmethod\n    def setup_context(ctx, inputs, output):\n        # ctx is a context object that can be used to stash information\n        # for backward computation\n        tensor, p = inputs\n        ctx.save_for_backward(tensor)\n        ctx.p = p\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        # We return as many input gradients as there were arguments.\n        # Gradients of non-Tensor arguments to forward must be None.\n        tensor, = ctx.saved_tensors\n        p = ctx.p\n        return grad_output * p * tensor**(p-1), None",
      "metadata": {},
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": "assert torch.all(Power.apply(torch.tensor([1, 2, 3]), 0) == torch.tensor([1, 1, 1]))\nassert torch.all(Power.apply(torch.tensor([1, 2, 3]), 2) == torch.tensor([1, 4, 9]))",
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "all() received an invalid combination of arguments - got (bool), but expected one of:\n * (Tensor input, *, Tensor out = None)\n * (Tensor input, tuple of ints dim = None, bool keepdim = False, *, Tensor out = None)\n * (Tensor input, int dim, bool keepdim = False, *, Tensor out = None)\n * (Tensor input, name dim, bool keepdim = False, *, Tensor out = None)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPower\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mall(Power\u001b[38;5;241m.\u001b[39mapply(torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m9\u001b[39m])))\n",
            "\u001b[0;31mTypeError\u001b[0m: all() received an invalid combination of arguments - got (bool), but expected one of:\n * (Tensor input, *, Tensor out = None)\n * (Tensor input, tuple of ints dim = None, bool keepdim = False, *, Tensor out = None)\n * (Tensor input, int dim, bool keepdim = False, *, Tensor out = None)\n * (Tensor input, name dim, bool keepdim = False, *, Tensor out = None)\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": "#### 3. Многочлен (3 балла)\nНайдите корень (он один) заданного полинома (очень хорошего!) с точностью до пяти знаков после запятой:\n1. Используя бинарный поиск https://en.wikipedia.org/wiki/Binary_search_algorithm\n2. Используя метод Ньютона https://en.wikipedia.org/wiki/Newton%27s_method\n   \n   Задаётся начальное приближение вблизи предположительного корня, после чего строится касательная к графику исследуемой функции в точке приближения, для которой находится пересечение с осью абсцисс. Эта точка берётся в качестве следующего приближения. И так далее, пока не будет достигнута необходимая точность.\n   \n   (hint: для вычисления производных используйте метод `backward()`)\n   \n   $x_{n+1} = x_{n} - \\frac{f(x_n)}{f'(x_n)}$\n\nСравните скорость методов с помощью `%%timeit`, т.е. оцените, какой из них найдёт ответ быстрее",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from typing import Callable\n\nPolynomial = Callable[[torch.FloatTensor], torch.FloatTensor]\ntorch.set_printoptions(precision=6)\n\ndef poly(x: torch.FloatTensor) -> torch.FloatTensor:\n    return x**7 + 5 * x**3 + 17 * x - 9",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "def bin_search_find_zero(poly: Polynomial) -> torch.FloatTensor:\n    \"\"\"Функция для бинарного поиска\"\"\"\n    l = torch.FloatTensor([0.])\n    r = torch.FloatTensor([1.])\n    tol = 1e-5\n    while r - l > torch.FloatTensor([tol]):\n        middle = l + (r - l) / 2\n        if poly(middle) < 0:\n            l = middle\n        else:\n            r = middle\n    return l",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "def newton_find_zero(poly: Polynomial) -> torch.FloatTensor:\n    \"\"\"Функция для метода Ньютона\"\"\"\n\n    # первое приближение (не забываем про то, что понадобится градиент!)\n    x = torch.tensor([0.], dtype=torch.float, requires_grad=True)\n\n    # останавливаемся, если значение функции достаточно близко к нулю\n    tol = 10**-5\n\n    # значение\n    val = poly(x)\n\n    # цикл обновления\n    while abs(val) > tol:  # когда останавливаемся?\n        # получаем градиент, обновляем значение x, оцениваем f(x)\n        # hint: нужны ли нам градиенты, когда мы обновляем x?\n        # hint: не забываем про обнуление градиента с прошлых шагов\n        val.backward()\n        with torch.no_grad():\n            x = x - val / x.grad\n        x.requires_grad = True\n        val = poly(x)\n        x.grad = None\n    return x",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "x = newton_find_zero(poly)\nprint(x)\nprint(poly(x))",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "%%timeit\nx = bin_search_find_zero(poly)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "%%timeit\nx = newton_find_zero(poly)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}