{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация и нормализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании вам предстоит реализовать два вида нормализации: по батчам (BatchNorm1d) и по признакам (LayerNorm1d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, NamedTuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Реализация BatchNorm1d и LayerNorm1d."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. (2 балла) Реализуйте BatchNorm1d\n",
    "\n",
    "Подсказка: чтобы хранить текущие значения среднего и дисперсии, вам потребуется метод `torch.nn.Module.register_buffer`, ознакомьтесь с документацией к нему. Подумайте, какие проблемы возникнут, если вы будете просто сохранять ваши значения в тензор.\n",
    "\n",
    "\n",
    "Важно помнить:\n",
    "- Понятно, что нормализацию мы добавляем после очередного слоя с параметрами, но до применения функции активации или после? Подумайте, есть ли у одного из этих способов преимущества над другим.\n",
    "- Модуль нормализации по батчам работает по-разному при обучении и при валидации, и ему нужно понимать, в каком он состоянии. Эта информация доступна в атрибуте модуля `self.training: bool`, его значение определит ветвление логики в вашей реализации метода `forward`.\n",
    "- Переключение модулей между режимами осуществляется вызовами у объекта модели методов `.train()` (переключение в режим обучения) и `.eval()` (переключение в режим валидации) Почитайте документацию к этим методам. Ваши функции `train_epoch` и `test_epoch` теперь должны переводить модель в нужный режим перед началом обработки данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm1d(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_features: int, momentum: float = 0.9, eps: float = 1e-5\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.scale = nn.Parameter(torch.ones(num_features))\n",
    "        self.shift = nn.Parameter(torch.zeros(num_features))\n",
    "        self.register_buffer(\"running_mean\", torch.zeros(num_features))\n",
    "        self.register_buffer(\"running_var\", torch.ones(num_features))\n",
    "        self.momentum = momentum\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        print(self.training)\n",
    "        if self.training:\n",
    "            mean = torch.mean(x, dim=0)\n",
    "            var = torch.var(x, dim=0, unbiased=False)\n",
    "            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * mean\n",
    "            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * var\n",
    "        else:\n",
    "            mean = self.running_mean\n",
    "            var = self.running_var\n",
    "        x_normalized = self.scale * ((x - mean.view(1, -1)) / torch.sqrt(var.view(1, -1) + self.eps)) + self.shift\n",
    "        return x_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. (1 балл) Реализуйте LayerNorm1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отличия LayerNorm от BatchNorm - в том, что расчёт средних и дисперсий в BatchNorm происходит вдоль размерности батча (см. рисунок слева), а в LayerNorm - вдоль размерности признаков (см. рисунок справа).\n",
    "\n",
    "<img src=\"../attachments/norm.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm1d(nn.Module):\n",
    "    def __init__(self, num_features: int, eps: float = 1e-5) -> None:\n",
    "        super(LayerNorm1d, self).__init__()\n",
    "        self.scale = nn.Parameter(torch.ones(num_features))\n",
    "        self.shift = nn.Parameter(torch.zeros(num_features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        mean = torch.mean(x, dim=-1, keepdim=True)\n",
    "        var = torch.var(x, dim=-1, keepdim=True, unbiased=False)\n",
    "        x_normalized = self.scale * ((x - mean) / torch.sqrt(var + self.eps)) + self.shift\n",
    "        return x_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замечание: явных тестов на корректность в этом задании нет, так как конкретные реализации могут давать немного разные результаты. Но вы можете проверить корректность своей реализации в эксперименте сами, нормализация должна немного исправлять проблемы неудачной инициализации. Ну и как минимум вы можете вручную проверить, что ваши активации действительно нормализуются в результате применения вашего модуля."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Эксперименты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании ваша задача - проверить, какие из приёмов хорошо справляются с нездоровыми активациями в промежуточных слоях. Вам будет дана базовая модель, у которой есть проблемы с инициализацией параметров, попробуйте несколько приёмов для устранения проблем обучения:\n",
    "1. Хорошая инициализация параметров\n",
    "2. Ненасыщаемая функция активации (например, `F.leaky_relu`)\n",
    "3. Нормализация по батчам или по признакам (можно использовать встроенные `nn.BatchNorm1d` и `nn.LayerNorm`)\n",
    "4. Более продвинутый оптимизатор (`torch.optim.RMSprop`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0. Подготовка: датасет, функции для обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверять наши гипотезы будем на датасете MNIST, для отладки добавим в функции для обучения возможность использовать только несколько батчей данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    \"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    \"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(\n",
    "    batch: tuple[torch.Tensor, torch.Tensor],\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    ") -> torch.Tensor:\n",
    "    # прогоняем батч через модель\n",
    "    x, y = batch\n",
    "    logits = model(x)\n",
    "    # оцениваем значение ошибки\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    # обновляем параметры\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    # возвращаем значение функции ошибки для логирования\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    dataloader: DataLoader,\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    max_batches: int = 100,\n",
    ") -> Tensor:\n",
    "    model.train()\n",
    "    loss_values: list[float] = []\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        loss = training_step(batch, model, optimizer)\n",
    "        loss_values.append(loss.item())\n",
    "        if i == max_batches:\n",
    "            break\n",
    "    return torch.tensor(loss_values).mean()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_epoch(\n",
    "    dataloader: DataLoader, model: nn.Module, max_batches: int = 100\n",
    ") -> Tensor:\n",
    "    model.eval()\n",
    "    loss_values: list[float] = []\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        x, y = batch\n",
    "        logits = model(x)\n",
    "        # оцениваем значение ошибки\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        loss_values.append(loss.item())\n",
    "        if i == max_batches:\n",
    "            break\n",
    "    return torch.tensor(loss_values).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Определение класса модели (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства проведения экспериментов мы немного усложним создание модели, чтобы можно было задать разные способы инициализации параметров и нормализации промежуточных активаций, не меняя определение класса.\n",
    "\n",
    "Добавьте в метод `__init__`:\n",
    "- аргумент, который позволит использовать разные функции активации для промежуточных слоёв\n",
    "- аргумент, который позволит задавать разные способы нормализации: `None` (без нормализации), `nn.BatchNorm` и `nn.LayerNorm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_std_normal(model: nn.Module) -> None:\n",
    "    \"\"\"Функция для инициализации параметров модели стандартным нормальным распределением.\"\"\"\n",
    "    for param in model.parameters():\n",
    "        torch.nn.init.normal_(param.data, mean=0, std=1)\n",
    "\n",
    "def init_kaiming_normal(model: nn.Module) -> None:\n",
    "    nn.init.kaiming_normal_(model.fc1.weight)\n",
    "    nn.init.kaiming_normal_(model.fc2.weight)\n",
    "\n",
    "from typing import Type\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Базовая модель для экспериментов\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): размерность входных признаков\n",
    "        hidden_dim (int): размерност скрытого слоя\n",
    "        output_dim (int): кол-во классов\n",
    "        act_fn (Callable[[Tensor], Tensor], optional): Функция активации. Defaults to F.tanh.\n",
    "        init_fn (Callable[[nn.Module], None], optional): Функция для инициализации. Defaults to init_std_normal.\n",
    "        norm (Type[nn.BatchNorm1d  |  nn.LayerNorm] | None, optional): Способ нормализации промежуточных активаций.\n",
    "            Defaults to None.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int,\n",
    "        output_dim: int,\n",
    "        act_fn: Callable[[Tensor], Tensor] = F.tanh,\n",
    "        init_fn: Callable[[nn.Module], None] = init_std_normal,\n",
    "        norm: Type[nn.BatchNorm1d | nn.LayerNorm] | None = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        # теперь линейные слои будем задавать\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.act_fn = act_fn\n",
    "        self.norm = norm(hidden_dim) if norm else None\n",
    "\n",
    "        # reinitialize parameters\n",
    "        init_fn(self)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        h = self.fc1.forward(x.flatten(1))\n",
    "        # here you can do normalization\n",
    "        if self.norm:\n",
    "            h = self.norm(h)\n",
    "        return self.fc2.forward(self.act_fn(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Эксперименты (7 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведите по 3 эксперимента с каждой из модификаций с разными значениями `seed`, соберите статистику значений тестовой ошибки после 10 эпох обучения, сделайте выводы о том, что работает лучше\n",
    "\n",
    "Проверяем:\n",
    "1. Метод инициализации весов модели: $\\mathcal{N}(0, 1)$ / Kaiming normal\n",
    "2. Функция активации: tanh /  (или любая другая без насыщения)\n",
    "3. Слой нормализации: None / BatchNorm / LayerNorm\n",
    "4. Выбранный оптимизатор: SGD / RMSprop / Adam\n",
    "\n",
    "Итого у нас 7 экспериментов:\n",
    "- исходный (1)\n",
    "- смена инициализации (1)\n",
    "- смена нелинейности (1)\n",
    "- смена нормализации (2)\n",
    "- смена оптимизатора (2)\n",
    "\n",
    "Каждый эксперимент нужно повторить 3 раза с разными значениями random seed, посчитать среднее и вывести результаты в pandas.DataFrame.\n",
    "Можно дополнительно потестировать разные сочетания опций, например инициализация + нормализация\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы автоматизировать проведение экспериментов, можно использовать функцию, которая будет принимать все необходимые настройки эксперимента, запускать его и сохранять нужные метрики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    model_gen: Callable[[], nn.Module],\n",
    "    optim_gen: Callable[[nn.Module], torch.optim.Optimizer],\n",
    "    seed: int,\n",
    "    n_epochs: int = 10,\n",
    "    max_batches: int | None = None,\n",
    "    verbose: bool = False,\n",
    ") -> float:\n",
    "    \"\"\"Функция для запуска экспериментов.\n",
    "\n",
    "    Args:\n",
    "        model_gen (Callable[[], nn.Module]): Функция для создания модели\n",
    "        optim_gen (Callable[[nn.Module], torch.optim.Optimizer]): Функция для создания оптимизатора для модели\n",
    "        seed (int): random seed\n",
    "        n_epochs (int, optional): Число эпох обучения. Defaults to 10.\n",
    "        max_batches (int | None, optional): Если указано, только `max_batches` минибатчей\n",
    "            будет использоваться при обучении и тестировании. Defaults to None.\n",
    "        verbose (bool, optional): Выводить ли информацию для отладки. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        float: Значение ошибки на тестовой выборке в конце обучения\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    # создадим модель и выведем значение ошибки после инициализации\n",
    "    model = model_gen()\n",
    "    optim = optim_gen(model)\n",
    "    epoch_losses: list[float] = []\n",
    "    for i in range(n_epochs):\n",
    "        train_loss = train_epoch(train_loader, model, optim, max_batches=max_batches)\n",
    "        test_loss = test_epoch(test_loader, model, max_batches=max_batches)\n",
    "        if verbose:\n",
    "            print(f\"Epoch {i} train loss = {train_loss:.4f}\")\n",
    "            print(f\"Epoch {i} test loss = {test_loss:.4f}\")\n",
    "\n",
    "        epoch_losses.append(test_loss.item())\n",
    "\n",
    "    last_epoch_loss = epoch_losses[-1]\n",
    "    return last_epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример использования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss = 12.6168\n",
      "Epoch 0 test loss = 9.9327\n",
      "Epoch 1 train loss = 9.0954\n",
      "Epoch 1 test loss = 7.5498\n",
      "Epoch 2 train loss = 6.9607\n",
      "Epoch 2 test loss = 6.2342\n",
      "Epoch 3 train loss = 5.8992\n",
      "Epoch 3 test loss = 5.3655\n",
      "Epoch 4 train loss = 4.9951\n",
      "Epoch 4 test loss = 4.7433\n",
      "Epoch 5 train loss = 4.4778\n",
      "Epoch 5 test loss = 4.3001\n",
      "Epoch 6 train loss = 3.9693\n",
      "Epoch 6 test loss = 3.9605\n",
      "Epoch 7 train loss = 3.7261\n",
      "Epoch 7 test loss = 3.6844\n",
      "Epoch 8 train loss = 3.4223\n",
      "Epoch 8 test loss = 3.4538\n",
      "Epoch 9 train loss = 2.9975\n",
      "Epoch 9 test loss = 3.2638\n"
     ]
    }
   ],
   "source": [
    "losses = run_experiment(\n",
    "    model_gen=lambda: MLP(784, 128, 10, init_fn=init_std_normal, norm=None),\n",
    "    optim_gen=lambda x: torch.optim.SGD(x.parameters(), lr=0.01),\n",
    "    seed=42,\n",
    "    n_epochs=10,\n",
    "    max_batches=100,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства задания настроек эксперимента можно определять их с помощью класса `Experiment`, в котором можно также реализовать логику для строкового представления:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "hidden_dim = 128\n",
    "output_dim = len(train_dataset.classes)\n",
    "\n",
    "\n",
    "class Experiment(NamedTuple):\n",
    "    init_fn: Callable[[nn.Module], None]\n",
    "    act_fn: Callable[[Tensor], Tensor]\n",
    "    norm: Type[nn.BatchNorm1d | nn.LayerNorm] | None\n",
    "    optim_cls: Type[torch.optim.Optimizer]\n",
    "\n",
    "    @property\n",
    "    def model_gen(self) -> Callable[[], nn.Module]:\n",
    "        return lambda: MLP(\n",
    "            input_dim, hidden_dim, output_dim, init_fn=self.init_fn, norm=self.norm, act_fn=self.act_fn\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def optim_gen(self) -> Callable[[nn.Module], torch.optim.Optimizer]:\n",
    "        return lambda x: self.optim_cls(x.parameters(), lr=0.01)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        # TODO: попробуйте сделать представление эксперимента более читаемым\n",
    "        # representation = (\"Метод инициализации весов модели:\" + str(self.init_fn.__name__)\n",
    "        #                     + \"\\n\" + \"Функция активации:\" + str(self.act_fn.__name__)\n",
    "        #                     + \"\\n\" + \"Слой нормализации:\" + str(self.norm.__name__ if self.norm is not None else None)\n",
    "        #                     + \"\\n\" + \"Оптимизатор:\" + str(self.optim_cls.__name__) + '\\n')\n",
    "        representation = ('Метод инициализации весов модели: ' + str(self.init_fn.__name__) + ', ' + 'Функция активации: '\n",
    "                          + str(self.act_fn.__name__) + ', ' + 'Слой нормализации: ' + str(self.norm.__name__ if self.norm is not None else None)\n",
    "                          + ', ' + 'Оптимизатор: ' + str(self.optim_cls.__name__))\n",
    "        return representation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описываем все эксперименты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: SGD,\n",
       " Метод инициализации весов модели: init_kaiming_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: SGD,\n",
       " Метод инициализации весов модели: init_std_normal, Функция активации: silu, Слой нормализации: None, Оптимизатор: SGD,\n",
       " Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: LayerNorm, Оптимизатор: SGD,\n",
       " Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: BatchNorm1d, Оптимизатор: SGD,\n",
       " Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: RMSprop,\n",
       " Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: Adam]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options = [\n",
    "    Experiment(\n",
    "        init_fn=init_std_normal,\n",
    "        act_fn=F.tanh,\n",
    "        norm=None,\n",
    "        optim_cls=torch.optim.SGD,\n",
    "    ),\n",
    "    Experiment(\n",
    "        init_fn=init_kaiming_normal,\n",
    "        act_fn=F.tanh,\n",
    "        norm=None,\n",
    "        optim_cls=torch.optim.SGD,\n",
    "    ),\n",
    "    Experiment(\n",
    "        init_fn=init_std_normal,\n",
    "        act_fn=F.silu,\n",
    "        norm=None,\n",
    "        optim_cls=torch.optim.SGD,\n",
    "    ),\n",
    "    Experiment(\n",
    "        init_fn=init_std_normal,\n",
    "        act_fn=F.tanh,\n",
    "        norm=nn.LayerNorm,\n",
    "        optim_cls=torch.optim.SGD,\n",
    "    ),\n",
    "    Experiment(\n",
    "        init_fn=init_std_normal,\n",
    "        act_fn=F.tanh,\n",
    "        norm=nn.BatchNorm1d,\n",
    "        optim_cls=torch.optim.SGD,\n",
    "    ),\n",
    "    Experiment(\n",
    "        init_fn=init_std_normal,\n",
    "        act_fn=F.tanh,\n",
    "        norm=None,\n",
    "        optim_cls=torch.optim.RMSprop,\n",
    "    ),\n",
    "    Experiment(\n",
    "        init_fn=init_std_normal,\n",
    "        act_fn=F.tanh,\n",
    "        norm=None,\n",
    "        optim_cls=torch.optim.Adam,\n",
    "    ),\n",
    "]\n",
    "\n",
    "options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем расчёты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss = 11.7281\n",
      "Epoch 0 test loss = 8.6669\n",
      "Epoch 1 train loss = 7.3093\n",
      "Epoch 1 test loss = 6.1118\n",
      "Epoch 2 train loss = 5.4957\n",
      "Epoch 2 test loss = 4.8238\n",
      "Epoch 3 train loss = 4.4830\n",
      "Epoch 3 test loss = 4.0405\n",
      "Epoch 4 train loss = 3.8325\n",
      "Epoch 4 test loss = 3.5157\n",
      "Epoch 5 train loss = 3.3787\n",
      "Epoch 5 test loss = 3.1404\n",
      "Epoch 6 train loss = 3.0433\n",
      "Epoch 6 test loss = 2.8587\n",
      "Epoch 7 train loss = 2.7844\n",
      "Epoch 7 test loss = 2.6378\n",
      "Epoch 8 train loss = 2.5767\n",
      "Epoch 8 test loss = 2.4578\n",
      "Epoch 9 train loss = 2.4053\n",
      "Epoch 9 test loss = 2.3110\n",
      "Epoch 0 train loss = 11.4157\n",
      "Epoch 0 test loss = 8.5777\n",
      "Epoch 1 train loss = 7.1368\n",
      "Epoch 1 test loss = 5.9516\n",
      "Epoch 2 train loss = 5.2834\n",
      "Epoch 2 test loss = 4.6240\n",
      "Epoch 3 train loss = 4.2749\n",
      "Epoch 3 test loss = 3.8606\n",
      "Epoch 4 train loss = 3.6567\n",
      "Epoch 4 test loss = 3.3595\n",
      "Epoch 5 train loss = 3.2366\n",
      "Epoch 5 test loss = 3.0058\n",
      "Epoch 6 train loss = 2.9283\n",
      "Epoch 6 test loss = 2.7412\n",
      "Epoch 7 train loss = 2.6911\n",
      "Epoch 7 test loss = 2.5331\n",
      "Epoch 8 train loss = 2.5022\n",
      "Epoch 8 test loss = 2.3649\n",
      "Epoch 9 train loss = 2.3476\n",
      "Epoch 9 test loss = 2.2258\n",
      "Epoch 0 train loss = 10.7465\n",
      "Epoch 0 test loss = 7.8783\n",
      "Epoch 1 train loss = 6.5376\n",
      "Epoch 1 test loss = 5.5533\n",
      "Epoch 2 train loss = 4.9444\n",
      "Epoch 2 test loss = 4.3784\n",
      "Epoch 3 train loss = 4.0560\n",
      "Epoch 3 test loss = 3.6751\n",
      "Epoch 4 train loss = 3.4902\n",
      "Epoch 4 test loss = 3.2076\n",
      "Epoch 5 train loss = 3.0986\n",
      "Epoch 5 test loss = 2.8734\n",
      "Epoch 6 train loss = 2.8094\n",
      "Epoch 6 test loss = 2.6221\n",
      "Epoch 7 train loss = 2.5862\n",
      "Epoch 7 test loss = 2.4273\n",
      "Epoch 8 train loss = 2.4091\n",
      "Epoch 8 test loss = 2.2702\n",
      "Epoch 9 train loss = 2.2646\n",
      "Epoch 9 test loss = 2.1414\n",
      "Epoch 0 train loss = 1.4651\n",
      "Epoch 0 test loss = 0.9488\n",
      "Epoch 1 train loss = 0.8091\n",
      "Epoch 1 test loss = 0.6750\n",
      "Epoch 2 train loss = 0.6363\n",
      "Epoch 2 test loss = 0.5640\n",
      "Epoch 3 train loss = 0.5534\n",
      "Epoch 3 test loss = 0.5023\n",
      "Epoch 4 train loss = 0.5033\n",
      "Epoch 4 test loss = 0.4622\n",
      "Epoch 5 train loss = 0.4691\n",
      "Epoch 5 test loss = 0.4342\n",
      "Epoch 6 train loss = 0.4440\n",
      "Epoch 6 test loss = 0.4129\n",
      "Epoch 7 train loss = 0.4245\n",
      "Epoch 7 test loss = 0.3963\n",
      "Epoch 8 train loss = 0.4089\n",
      "Epoch 8 test loss = 0.3830\n",
      "Epoch 9 train loss = 0.3960\n",
      "Epoch 9 test loss = 0.3717\n",
      "Epoch 0 train loss = 1.4539\n",
      "Epoch 0 test loss = 0.9471\n",
      "Epoch 1 train loss = 0.8021\n",
      "Epoch 1 test loss = 0.6676\n",
      "Epoch 2 train loss = 0.6268\n",
      "Epoch 2 test loss = 0.5551\n",
      "Epoch 3 train loss = 0.5439\n",
      "Epoch 3 test loss = 0.4932\n",
      "Epoch 4 train loss = 0.4942\n",
      "Epoch 4 test loss = 0.4539\n",
      "Epoch 5 train loss = 0.4606\n",
      "Epoch 5 test loss = 0.4256\n",
      "Epoch 6 train loss = 0.4360\n",
      "Epoch 6 test loss = 0.4047\n",
      "Epoch 7 train loss = 0.4170\n",
      "Epoch 7 test loss = 0.3883\n",
      "Epoch 8 train loss = 0.4018\n",
      "Epoch 8 test loss = 0.3750\n",
      "Epoch 9 train loss = 0.3892\n",
      "Epoch 9 test loss = 0.3641\n",
      "Epoch 0 train loss = 1.4576\n",
      "Epoch 0 test loss = 0.9615\n",
      "Epoch 1 train loss = 0.8230\n",
      "Epoch 1 test loss = 0.6858\n",
      "Epoch 2 train loss = 0.6459\n",
      "Epoch 2 test loss = 0.5732\n",
      "Epoch 3 train loss = 0.5607\n",
      "Epoch 3 test loss = 0.5106\n",
      "Epoch 4 train loss = 0.5092\n",
      "Epoch 4 test loss = 0.4700\n",
      "Epoch 5 train loss = 0.4741\n",
      "Epoch 5 test loss = 0.4411\n",
      "Epoch 6 train loss = 0.4484\n",
      "Epoch 6 test loss = 0.4193\n",
      "Epoch 7 train loss = 0.4285\n",
      "Epoch 7 test loss = 0.4023\n",
      "Epoch 8 train loss = 0.4125\n",
      "Epoch 8 test loss = 0.3886\n",
      "Epoch 9 train loss = 0.3994\n",
      "Epoch 9 test loss = 0.3771\n",
      "Epoch 0 train loss = 28.5657\n",
      "Epoch 0 test loss = 13.3214\n",
      "Epoch 1 train loss = 10.6962\n",
      "Epoch 1 test loss = 8.3496\n",
      "Epoch 2 train loss = 7.5157\n",
      "Epoch 2 test loss = 6.4797\n",
      "Epoch 3 train loss = 6.0431\n",
      "Epoch 3 test loss = 5.4547\n",
      "Epoch 4 train loss = 5.1567\n",
      "Epoch 4 test loss = 4.7766\n",
      "Epoch 5 train loss = 4.5543\n",
      "Epoch 5 test loss = 4.3126\n",
      "Epoch 6 train loss = 4.1122\n",
      "Epoch 6 test loss = 3.9538\n",
      "Epoch 7 train loss = 3.7693\n",
      "Epoch 7 test loss = 3.6884\n",
      "Epoch 8 train loss = 3.4937\n",
      "Epoch 8 test loss = 3.4559\n",
      "Epoch 9 train loss = 3.2638\n",
      "Epoch 9 test loss = 3.2676\n",
      "Epoch 0 train loss = 28.8481\n",
      "Epoch 0 test loss = 13.7424\n",
      "Epoch 1 train loss = 11.0900\n",
      "Epoch 1 test loss = 8.8841\n",
      "Epoch 2 train loss = 8.0375\n",
      "Epoch 2 test loss = 7.0036\n",
      "Epoch 3 train loss = 6.5881\n",
      "Epoch 3 test loss = 5.9641\n",
      "Epoch 4 train loss = 5.7031\n",
      "Epoch 4 test loss = 5.2727\n",
      "Epoch 5 train loss = 5.0849\n",
      "Epoch 5 test loss = 4.7871\n",
      "Epoch 6 train loss = 4.6215\n",
      "Epoch 6 test loss = 4.3996\n",
      "Epoch 7 train loss = 4.2604\n",
      "Epoch 7 test loss = 4.0897\n",
      "Epoch 8 train loss = 3.9642\n",
      "Epoch 8 test loss = 3.8442\n",
      "Epoch 9 train loss = 3.7136\n",
      "Epoch 9 test loss = 3.6335\n",
      "Epoch 0 train loss = 26.7178\n",
      "Epoch 0 test loss = 12.5789\n",
      "Epoch 1 train loss = 10.3635\n",
      "Epoch 1 test loss = 8.1700\n",
      "Epoch 2 train loss = 7.6166\n",
      "Epoch 2 test loss = 6.5380\n",
      "Epoch 3 train loss = 6.3051\n",
      "Epoch 3 test loss = 5.6019\n",
      "Epoch 4 train loss = 5.4958\n",
      "Epoch 4 test loss = 4.9583\n",
      "Epoch 5 train loss = 4.9208\n",
      "Epoch 5 test loss = 4.4914\n",
      "Epoch 6 train loss = 4.4896\n",
      "Epoch 6 test loss = 4.1378\n",
      "Epoch 7 train loss = 4.1501\n",
      "Epoch 7 test loss = 3.8549\n",
      "Epoch 8 train loss = 3.8696\n",
      "Epoch 8 test loss = 3.6111\n",
      "Epoch 9 train loss = 3.6360\n",
      "Epoch 9 test loss = 3.3998\n",
      "Epoch 0 train loss = 5.7650\n",
      "Epoch 0 test loss = 3.8939\n",
      "Epoch 1 train loss = 3.3830\n",
      "Epoch 1 test loss = 2.8104\n",
      "Epoch 2 train loss = 2.5868\n",
      "Epoch 2 test loss = 2.2427\n",
      "Epoch 3 train loss = 2.1369\n",
      "Epoch 3 test loss = 1.8991\n",
      "Epoch 4 train loss = 1.8510\n",
      "Epoch 4 test loss = 1.6722\n",
      "Epoch 5 train loss = 1.6536\n",
      "Epoch 5 test loss = 1.5096\n",
      "Epoch 6 train loss = 1.5082\n",
      "Epoch 6 test loss = 1.3875\n",
      "Epoch 7 train loss = 1.3964\n",
      "Epoch 7 test loss = 1.2912\n",
      "Epoch 8 train loss = 1.3069\n",
      "Epoch 8 test loss = 1.2139\n",
      "Epoch 9 train loss = 1.2336\n",
      "Epoch 9 test loss = 1.1499\n",
      "Epoch 0 train loss = 6.4819\n",
      "Epoch 0 test loss = 3.9512\n",
      "Epoch 1 train loss = 3.4205\n",
      "Epoch 1 test loss = 2.8113\n",
      "Epoch 2 train loss = 2.5732\n",
      "Epoch 2 test loss = 2.2279\n",
      "Epoch 3 train loss = 2.1060\n",
      "Epoch 3 test loss = 1.8840\n",
      "Epoch 4 train loss = 1.8155\n",
      "Epoch 4 test loss = 1.6560\n",
      "Epoch 5 train loss = 1.6164\n",
      "Epoch 5 test loss = 1.4949\n",
      "Epoch 6 train loss = 1.4716\n",
      "Epoch 6 test loss = 1.3728\n",
      "Epoch 7 train loss = 1.3605\n",
      "Epoch 7 test loss = 1.2768\n",
      "Epoch 8 train loss = 1.2727\n",
      "Epoch 8 test loss = 1.1995\n",
      "Epoch 9 train loss = 1.2010\n",
      "Epoch 9 test loss = 1.1365\n",
      "Epoch 0 train loss = 5.6993\n",
      "Epoch 0 test loss = 4.2503\n",
      "Epoch 1 train loss = 3.5763\n",
      "Epoch 1 test loss = 3.0196\n",
      "Epoch 2 train loss = 2.6936\n",
      "Epoch 2 test loss = 2.3541\n",
      "Epoch 3 train loss = 2.1972\n",
      "Epoch 3 test loss = 1.9670\n",
      "Epoch 4 train loss = 1.8907\n",
      "Epoch 4 test loss = 1.7181\n",
      "Epoch 5 train loss = 1.6814\n",
      "Epoch 5 test loss = 1.5423\n",
      "Epoch 6 train loss = 1.5283\n",
      "Epoch 6 test loss = 1.4104\n",
      "Epoch 7 train loss = 1.4113\n",
      "Epoch 7 test loss = 1.3079\n",
      "Epoch 8 train loss = 1.3184\n",
      "Epoch 8 test loss = 1.2248\n",
      "Epoch 9 train loss = 1.2425\n",
      "Epoch 9 test loss = 1.1573\n",
      "Epoch 0 train loss = 6.7186\n",
      "Epoch 0 test loss = 4.6695\n",
      "Epoch 1 train loss = 4.0104\n",
      "Epoch 1 test loss = 3.3164\n",
      "Epoch 2 train loss = 3.0196\n",
      "Epoch 2 test loss = 2.5634\n",
      "Epoch 3 train loss = 2.4782\n",
      "Epoch 3 test loss = 2.1258\n",
      "Epoch 4 train loss = 2.1273\n",
      "Epoch 4 test loss = 1.8687\n",
      "Epoch 5 train loss = 1.8880\n",
      "Epoch 5 test loss = 1.6613\n",
      "Epoch 6 train loss = 1.7092\n",
      "Epoch 6 test loss = 1.5091\n",
      "Epoch 7 train loss = 1.5775\n",
      "Epoch 7 test loss = 1.3870\n",
      "Epoch 8 train loss = 1.4640\n",
      "Epoch 8 test loss = 1.2901\n",
      "Epoch 9 train loss = 1.3730\n",
      "Epoch 9 test loss = 1.2065\n",
      "Epoch 0 train loss = 8.3743\n",
      "Epoch 0 test loss = 5.1026\n",
      "Epoch 1 train loss = 4.2295\n",
      "Epoch 1 test loss = 3.3411\n",
      "Epoch 2 train loss = 3.0639\n",
      "Epoch 2 test loss = 2.6117\n",
      "Epoch 3 train loss = 2.4749\n",
      "Epoch 3 test loss = 2.1661\n",
      "Epoch 4 train loss = 2.1096\n",
      "Epoch 4 test loss = 1.8565\n",
      "Epoch 5 train loss = 1.8561\n",
      "Epoch 5 test loss = 1.6492\n",
      "Epoch 6 train loss = 1.6576\n",
      "Epoch 6 test loss = 1.5037\n",
      "Epoch 7 train loss = 1.5216\n",
      "Epoch 7 test loss = 1.3829\n",
      "Epoch 8 train loss = 1.4024\n",
      "Epoch 8 test loss = 1.2803\n",
      "Epoch 9 train loss = 1.3107\n",
      "Epoch 9 test loss = 1.1985\n",
      "Epoch 0 train loss = 7.1427\n",
      "Epoch 0 test loss = 5.1089\n",
      "Epoch 1 train loss = 4.3327\n",
      "Epoch 1 test loss = 3.4756\n",
      "Epoch 2 train loss = 3.2047\n",
      "Epoch 2 test loss = 2.6610\n",
      "Epoch 3 train loss = 2.5767\n",
      "Epoch 3 test loss = 2.1648\n",
      "Epoch 4 train loss = 2.1848\n",
      "Epoch 4 test loss = 1.8603\n",
      "Epoch 5 train loss = 1.9261\n",
      "Epoch 5 test loss = 1.6486\n",
      "Epoch 6 train loss = 1.7331\n",
      "Epoch 6 test loss = 1.4726\n",
      "Epoch 7 train loss = 1.5858\n",
      "Epoch 7 test loss = 1.3600\n",
      "Epoch 8 train loss = 1.4656\n",
      "Epoch 8 test loss = 1.2503\n",
      "Epoch 9 train loss = 1.3730\n",
      "Epoch 9 test loss = 1.1698\n",
      "Epoch 0 train loss = 0.6901\n",
      "Epoch 0 test loss = 0.3383\n",
      "Epoch 1 train loss = 0.3051\n",
      "Epoch 1 test loss = 0.2604\n",
      "Epoch 2 train loss = 0.2448\n",
      "Epoch 2 test loss = 0.2369\n",
      "Epoch 3 train loss = 0.2038\n",
      "Epoch 3 test loss = 0.1951\n",
      "Epoch 4 train loss = 0.1809\n",
      "Epoch 4 test loss = 0.2304\n",
      "Epoch 5 train loss = 0.1719\n",
      "Epoch 5 test loss = 0.1989\n",
      "Epoch 6 train loss = 0.1668\n",
      "Epoch 6 test loss = 0.1783\n",
      "Epoch 7 train loss = 0.1572\n",
      "Epoch 7 test loss = 0.1612\n",
      "Epoch 8 train loss = 0.1421\n",
      "Epoch 8 test loss = 0.2034\n",
      "Epoch 9 train loss = 0.1360\n",
      "Epoch 9 test loss = 0.1878\n",
      "Epoch 0 train loss = 0.7063\n",
      "Epoch 0 test loss = 0.3922\n",
      "Epoch 1 train loss = 0.3065\n",
      "Epoch 1 test loss = 0.2688\n",
      "Epoch 2 train loss = 0.2456\n",
      "Epoch 2 test loss = 0.2230\n",
      "Epoch 3 train loss = 0.2181\n",
      "Epoch 3 test loss = 0.2052\n",
      "Epoch 4 train loss = 0.1919\n",
      "Epoch 4 test loss = 0.1898\n",
      "Epoch 5 train loss = 0.1712\n",
      "Epoch 5 test loss = 0.1853\n",
      "Epoch 6 train loss = 0.1612\n",
      "Epoch 6 test loss = 0.1811\n",
      "Epoch 7 train loss = 0.1508\n",
      "Epoch 7 test loss = 0.2023\n",
      "Epoch 8 train loss = 0.1432\n",
      "Epoch 8 test loss = 0.1790\n",
      "Epoch 9 train loss = 0.1321\n",
      "Epoch 9 test loss = 0.1761\n",
      "Epoch 0 train loss = 0.6644\n",
      "Epoch 0 test loss = 0.3481\n",
      "Epoch 1 train loss = 0.2991\n",
      "Epoch 1 test loss = 0.3153\n",
      "Epoch 2 train loss = 0.2401\n",
      "Epoch 2 test loss = 0.2713\n",
      "Epoch 3 train loss = 0.2077\n",
      "Epoch 3 test loss = 0.2169\n",
      "Epoch 4 train loss = 0.1881\n",
      "Epoch 4 test loss = 0.2825\n",
      "Epoch 5 train loss = 0.1738\n",
      "Epoch 5 test loss = 0.2266\n",
      "Epoch 6 train loss = 0.1579\n",
      "Epoch 6 test loss = 0.2050\n",
      "Epoch 7 train loss = 0.1523\n",
      "Epoch 7 test loss = 0.1879\n",
      "Epoch 8 train loss = 0.1402\n",
      "Epoch 8 test loss = 0.1670\n",
      "Epoch 9 train loss = 0.1393\n",
      "Epoch 9 test loss = 0.1945\n",
      "Epoch 0 train loss = 2.7270\n",
      "Epoch 0 test loss = 1.0702\n",
      "Epoch 1 train loss = 0.8274\n",
      "Epoch 1 test loss = 0.7049\n",
      "Epoch 2 train loss = 0.5345\n",
      "Epoch 2 test loss = 0.5378\n",
      "Epoch 3 train loss = 0.3939\n",
      "Epoch 3 test loss = 0.4629\n",
      "Epoch 4 train loss = 0.3003\n",
      "Epoch 4 test loss = 0.4131\n",
      "Epoch 5 train loss = 0.2361\n",
      "Epoch 5 test loss = 0.3780\n",
      "Epoch 6 train loss = 0.1927\n",
      "Epoch 6 test loss = 0.3505\n",
      "Epoch 7 train loss = 0.1593\n",
      "Epoch 7 test loss = 0.3260\n",
      "Epoch 8 train loss = 0.1339\n",
      "Epoch 8 test loss = 0.3130\n",
      "Epoch 9 train loss = 0.1144\n",
      "Epoch 9 test loss = 0.3057\n",
      "Epoch 0 train loss = 2.7110\n",
      "Epoch 0 test loss = 1.1351\n",
      "Epoch 1 train loss = 0.8640\n",
      "Epoch 1 test loss = 0.7394\n",
      "Epoch 2 train loss = 0.5699\n",
      "Epoch 2 test loss = 0.5909\n",
      "Epoch 3 train loss = 0.4092\n",
      "Epoch 3 test loss = 0.4987\n",
      "Epoch 4 train loss = 0.3112\n",
      "Epoch 4 test loss = 0.4303\n",
      "Epoch 5 train loss = 0.2458\n",
      "Epoch 5 test loss = 0.4016\n",
      "Epoch 6 train loss = 0.2003\n",
      "Epoch 6 test loss = 0.3727\n",
      "Epoch 7 train loss = 0.1657\n",
      "Epoch 7 test loss = 0.3414\n",
      "Epoch 8 train loss = 0.1392\n",
      "Epoch 8 test loss = 0.3302\n",
      "Epoch 9 train loss = 0.1192\n",
      "Epoch 9 test loss = 0.3176\n",
      "Epoch 0 train loss = 2.5702\n",
      "Epoch 0 test loss = 1.0113\n",
      "Epoch 1 train loss = 0.8425\n",
      "Epoch 1 test loss = 0.6698\n",
      "Epoch 2 train loss = 0.5551\n",
      "Epoch 2 test loss = 0.5280\n",
      "Epoch 3 train loss = 0.4030\n",
      "Epoch 3 test loss = 0.4382\n",
      "Epoch 4 train loss = 0.3083\n",
      "Epoch 4 test loss = 0.3787\n",
      "Epoch 5 train loss = 0.2423\n",
      "Epoch 5 test loss = 0.3482\n",
      "Epoch 6 train loss = 0.1971\n",
      "Epoch 6 test loss = 0.3295\n",
      "Epoch 7 train loss = 0.1612\n",
      "Epoch 7 test loss = 0.3030\n",
      "Epoch 8 train loss = 0.1347\n",
      "Epoch 8 test loss = 0.2916\n",
      "Epoch 9 train loss = 0.1153\n",
      "Epoch 9 test loss = 0.2889\n"
     ]
    }
   ],
   "source": [
    "seeds = [6, 12, 48]  # здесь вам нужно 3 разных значения\n",
    "results = []\n",
    "\n",
    "for option in options:\n",
    "    for seed in seeds:\n",
    "        loss = run_experiment(\n",
    "            model_gen=lambda: MLP(input_dim, hidden_dim, output_dim, init_fn=option.init_fn, act_fn=option.act_fn, norm=option.norm),\n",
    "            optim_gen=lambda x: option.optim_cls(x.parameters()),\n",
    "            seed=seed,\n",
    "            n_epochs=10,\n",
    "            max_batches=None,\n",
    "            verbose=True,\n",
    "        )\n",
    "        results.append([repr(option), seed, loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводим результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>options</th>\n",
       "      <th>seed</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: SGD</td>\n",
       "      <td>6</td>\n",
       "      <td>2.311021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: SGD</td>\n",
       "      <td>12</td>\n",
       "      <td>2.225786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: SGD</td>\n",
       "      <td>48</td>\n",
       "      <td>2.141401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Метод инициализации весов модели: init_kaiming_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: SGD</td>\n",
       "      <td>6</td>\n",
       "      <td>0.371709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Метод инициализации весов модели: init_kaiming_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: SGD</td>\n",
       "      <td>12</td>\n",
       "      <td>0.364070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Метод инициализации весов модели: init_kaiming_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: SGD</td>\n",
       "      <td>48</td>\n",
       "      <td>0.377117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: silu, Слой нормализации: None, Оптимизатор: SGD</td>\n",
       "      <td>6</td>\n",
       "      <td>3.267605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: silu, Слой нормализации: None, Оптимизатор: SGD</td>\n",
       "      <td>12</td>\n",
       "      <td>3.633480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: silu, Слой нормализации: None, Оптимизатор: SGD</td>\n",
       "      <td>48</td>\n",
       "      <td>3.399774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: LayerNorm, Оптимизатор: SGD</td>\n",
       "      <td>6</td>\n",
       "      <td>1.149888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: LayerNorm, Оптимизатор: SGD</td>\n",
       "      <td>12</td>\n",
       "      <td>1.136523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: LayerNorm, Оптимизатор: SGD</td>\n",
       "      <td>48</td>\n",
       "      <td>1.157307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: BatchNorm1d, Оптимизатор: SGD</td>\n",
       "      <td>6</td>\n",
       "      <td>1.206457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: BatchNorm1d, Оптимизатор: SGD</td>\n",
       "      <td>12</td>\n",
       "      <td>1.198500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: BatchNorm1d, Оптимизатор: SGD</td>\n",
       "      <td>48</td>\n",
       "      <td>1.169792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: RMSprop</td>\n",
       "      <td>6</td>\n",
       "      <td>0.187787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: RMSprop</td>\n",
       "      <td>12</td>\n",
       "      <td>0.176071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: RMSprop</td>\n",
       "      <td>48</td>\n",
       "      <td>0.194495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: Adam</td>\n",
       "      <td>6</td>\n",
       "      <td>0.305740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: Adam</td>\n",
       "      <td>12</td>\n",
       "      <td>0.317553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: Adam</td>\n",
       "      <td>48</td>\n",
       "      <td>0.288925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                         options  \\\n",
       "0          Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: SGD   \n",
       "1          Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: SGD   \n",
       "2          Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: SGD   \n",
       "3      Метод инициализации весов модели: init_kaiming_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: SGD   \n",
       "4      Метод инициализации весов модели: init_kaiming_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: SGD   \n",
       "5      Метод инициализации весов модели: init_kaiming_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: SGD   \n",
       "6          Метод инициализации весов модели: init_std_normal, Функция активации: silu, Слой нормализации: None, Оптимизатор: SGD   \n",
       "7          Метод инициализации весов модели: init_std_normal, Функция активации: silu, Слой нормализации: None, Оптимизатор: SGD   \n",
       "8          Метод инициализации весов модели: init_std_normal, Функция активации: silu, Слой нормализации: None, Оптимизатор: SGD   \n",
       "9     Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: LayerNorm, Оптимизатор: SGD   \n",
       "10    Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: LayerNorm, Оптимизатор: SGD   \n",
       "11    Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: LayerNorm, Оптимизатор: SGD   \n",
       "12  Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: BatchNorm1d, Оптимизатор: SGD   \n",
       "13  Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: BatchNorm1d, Оптимизатор: SGD   \n",
       "14  Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: BatchNorm1d, Оптимизатор: SGD   \n",
       "15     Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: RMSprop   \n",
       "16     Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: RMSprop   \n",
       "17     Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: RMSprop   \n",
       "18        Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: Adam   \n",
       "19        Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: Adam   \n",
       "20        Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: Adam   \n",
       "\n",
       "    seed      loss  \n",
       "0      6  2.311021  \n",
       "1     12  2.225786  \n",
       "2     48  2.141401  \n",
       "3      6  0.371709  \n",
       "4     12  0.364070  \n",
       "5     48  0.377117  \n",
       "6      6  3.267605  \n",
       "7     12  3.633480  \n",
       "8     48  3.399774  \n",
       "9      6  1.149888  \n",
       "10    12  1.136523  \n",
       "11    48  1.157307  \n",
       "12     6  1.206457  \n",
       "13    12  1.198500  \n",
       "14    48  1.169792  \n",
       "15     6  0.187787  \n",
       "16    12  0.176071  \n",
       "17    48  0.194495  \n",
       "18     6  0.305740  \n",
       "19    12  0.317553  \n",
       "20    48  0.288925  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>options</th>\n",
       "      <th>mean_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Метод инициализации весов модели: init_kaiming_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: SGD</td>\n",
       "      <td>0.370965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: silu, Слой нормализации: None, Оптимизатор: SGD</td>\n",
       "      <td>3.433620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: BatchNorm1d, Оптимизатор: SGD</td>\n",
       "      <td>1.191583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: LayerNorm, Оптимизатор: SGD</td>\n",
       "      <td>1.147906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: Adam</td>\n",
       "      <td>0.304073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: RMSprop</td>\n",
       "      <td>0.186117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: SGD</td>\n",
       "      <td>2.226069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                        options  \\\n",
       "0     Метод инициализации весов модели: init_kaiming_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: SGD   \n",
       "1         Метод инициализации весов модели: init_std_normal, Функция активации: silu, Слой нормализации: None, Оптимизатор: SGD   \n",
       "2  Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: BatchNorm1d, Оптимизатор: SGD   \n",
       "3    Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: LayerNorm, Оптимизатор: SGD   \n",
       "4        Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: Adam   \n",
       "5     Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: RMSprop   \n",
       "6         Метод инициализации весов модели: init_std_normal, Функция активации: tanh, Слой нормализации: None, Оптимизатор: SGD   \n",
       "\n",
       "   mean_loss  \n",
       "0   0.370965  \n",
       "1   3.433620  \n",
       "2   1.191583  \n",
       "3   1.147906  \n",
       "4   0.304073  \n",
       "5   0.186117  \n",
       "6   2.226069  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df = pd.DataFrame(results)\n",
    "df = df.set_axis(['options', 'seed', 'loss'], axis=1)\n",
    "display(df)\n",
    "print()\n",
    "df1 = df.groupby('options', as_index=False)['loss'].mean()\n",
    "df1 = df1.rename(columns = {'loss': 'mean_loss'})\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВЫВОДЫ:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Меньше всего тестовая ошибка при стандартной нормальной инициализации весов, использовании гиперболического тангенса\n",
    "в качестве функции активации, без использования нормализации данных, с оптимизатором RMSprop. Также можно видеть, \n",
    "что с таким методом инициализации весов ошибка не падала резко, что дает надежду на то, что инициализация оптимальна."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
